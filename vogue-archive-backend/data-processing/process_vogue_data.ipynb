{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAAcNNdeHaVk"
      },
      "source": [
        "# Vogue Archive Data Processing\n",
        "\n",
        "This notebook processes Vogue magazine data and creates vector embeddings for semantic search.\n",
        "\n",
        "**Run this in Google Colab for free GPU access**\n",
        "\n",
        "Runtime: ~20 minutes for 10k records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxou3UdbHaVk"
      },
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-T3HgYP_HaVk",
        "outputId": "953e9b9c-0f5a-4493-f1b0-ede05efd977d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.10.5)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (1.8.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers pinecone pandas tqdm pyarrow torch transformers ftfy regex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSjOWog_HaVl"
      },
      "source": [
        "## 2. Setup Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7_WMBAQaHaVl",
        "outputId": "bfc00561-a199-45c9-e5ef-1ea454ccdd47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'vogue-archive-clip' ready!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Your Pinecone API key\n",
        "PINECONE_API_KEY = \"pcsk_2JKS4Y_LNuT72kmgxsuWksy2LyqcQP5Q2iX626vPCwb2KEjj23Vf72a43ZWgNp6FcCJshz\"\n",
        "INDEX_NAME = \"vogue-archive-clip\"  # New index name for CLIP embeddings\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "# Create index if it doesn't exist\n",
        "# CLIP uses 512 dimensions (vs 384 for MiniLM)\n",
        "if INDEX_NAME not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,\n",
        "        dimension=512,  # CLIP ViT-B/32 dimension\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "index = pc.Index(INDEX_NAME)\n",
        "print(f\"Index '{INDEX_NAME}' ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkNHml28HaVl"
      },
      "source": [
        "## 3. Download Pre-computed Image Embeddings\n",
        "\n",
        "The dataset includes pre-computed CLIP image embeddings - we'll use these!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yXIKXdS0HaVl",
        "outputId": "6fecde7a-4016-4354-c311-b9694eb83cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pre-computed CLIP image embeddings (1.2GB - this will take a few minutes)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VogueRunway_image.npy: 100%|██████████| 1.22G/1.22G [02:12<00:00, 9.89MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading embeddings into memory...\n",
            "✓ Loaded 1,281,633 pre-computed CLIP image embeddings\n",
            "Embedding dimension: 512\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the base URL for the archive\n",
        "ARCHIVE_BASE_URL = \"https://archive.org/download/VogueRunway_dataset\"\n",
        "\n",
        "print(\"Downloading pre-computed CLIP image embeddings (1.2GB - this will take a few minutes)...\")\n",
        "embeddings_url = f\"{ARCHIVE_BASE_URL}/img_emb/VogueRunway_image.npy\"\n",
        "\n",
        "# Download with progress bar\n",
        "response = requests.get(embeddings_url, stream=True)\n",
        "total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "with open('VogueRunway_image.npy', 'wb') as f, tqdm(\n",
        "    desc=\"VogueRunway_image.npy\",\n",
        "    total=total_size,\n",
        "    unit='B',\n",
        "    unit_scale=True,\n",
        "    unit_divisor=1024,\n",
        ") as pbar:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "            pbar.update(len(chunk))\n",
        "\n",
        "print(\"\\nLoading embeddings into memory...\")\n",
        "# Load the embeddings\n",
        "image_embeddings = np.load('VogueRunway_image.npy')\n",
        "print(f\"✓ Loaded {len(image_embeddings):,} pre-computed CLIP image embeddings\")\n",
        "print(f\"Embedding dimension: {image_embeddings.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcnr8JXwHaVl"
      },
      "source": [
        "## 4. Load Vogue Runway Metadata\n",
        "\n",
        "Download metadata and match with embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JKsWS50HHaVl",
        "outputId": "16e55c18-6979-4920-bb25-84a6022347a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Vogue Runway metadata...\n",
            "Loading metadata...\n",
            "Total items: 1,281,633\n",
            "Total embeddings: 1,281,633\n",
            "\n",
            "Selected top 1000 items by aesthetic score\n",
            "\n",
            "Sample data:\n",
            "       key  designer  season  year  category   city\n",
            "0  0417267    Brioni  Spring  2019  Menswear   None\n",
            "1  0673432     Cinoh  Spring  2022      None  Tokyo\n",
            "2  0940024  Belstaff    Fall  2015  Menswear   None\n",
            "3  1088552  Belstaff    Fall  2015  Menswear   None\n",
            "4  0395237     Prada    Fall  2022  Menswear   None\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Define the base URL for the archive\n",
        "ARCHIVE_BASE_URL = \"https://archive.org/download/VogueRunway_dataset\"\n",
        "\n",
        "print(\"Downloading Vogue Runway metadata...\")\n",
        "url = f\"{ARCHIVE_BASE_URL}/VogueRunway.parquet\"\n",
        "\n",
        "# Download parquet file\n",
        "response = requests.get(url, stream=True)\n",
        "with open('VogueRunway.parquet', 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "        f.write(chunk)\n",
        "\n",
        "print(\"Loading metadata...\")\n",
        "df = pd.read_parquet('VogueRunway.parquet')\n",
        "\n",
        "print(f\"Total items: {len(df):,}\")\n",
        "print(f\"Total embeddings: {len(image_embeddings):,}\")\n",
        "\n",
        "# Take top items by aesthetic score (you can change 1000 to 10000 or 100000)\n",
        "NUM_ITEMS = 1000\n",
        "\n",
        "if 'aesthetic' in df.columns:\n",
        "    df = df.nlargest(NUM_ITEMS, 'aesthetic')\n",
        "    print(f\"\\nSelected top {NUM_ITEMS} items by aesthetic score\")\n",
        "else:\n",
        "    df = df.head(NUM_ITEMS)\n",
        "    print(f\"\\nTaking first {NUM_ITEMS} items\")\n",
        "\n",
        "# Reset index to get clean indices\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nSample data:\")\n",
        "print(df[['key', 'designer', 'season', 'year', 'category', 'city']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtbGhB-6HaVl"
      },
      "source": [
        "## 5. Match Embeddings with Metadata and Upload to Pinecone\n",
        "\n",
        "Use pre-computed image embeddings for multimodal search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iUvYyC7eHaVl",
        "outputId": "f62ba90c-5b73-418d-9a21-dbee096f381d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing 1000 items with pre-computed embeddings...\n",
            "Using embeddings indexed by key value\n",
            "Uploading in batches of 100...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:04<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Upload complete! 1000 vectors uploaded to Pinecone.\n",
            "\n",
            "Index stats: {'dimension': 512,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 1000}},\n",
            " 'total_vector_count': 1000,\n",
            " 'vector_type': 'dense'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Batch size for uploading\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def process_batch(batch_df, batch_start_idx):\n",
        "    \"\"\"Process a batch of records with pre-computed embeddings\"\"\"\n",
        "    vectors = []\n",
        "\n",
        "    for local_idx, (_, row) in enumerate(batch_df.iterrows()):\n",
        "        # Use the key to get the correct embedding\n",
        "        key = int(row['key'])\n",
        "\n",
        "        # Get embedding using the key as index\n",
        "        # The embeddings array is indexed by key value\n",
        "        if key < len(image_embeddings):\n",
        "            embedding = image_embeddings[key].tolist()\n",
        "        else:\n",
        "            print(f\"Warning: key {key} out of bounds, skipping\")\n",
        "            continue\n",
        "\n",
        "        # Prepare metadata\n",
        "        metadata = {\n",
        "            \"description\": f\"{row.get('designer', '')} {row.get('season', '')} {row.get('year', '')} {row.get('category', '')} {row.get('section', '')}\".strip(),\n",
        "            \"designer\": str(row.get('designer', '')),\n",
        "            \"season\": str(row.get('season', '')),\n",
        "            \"year\": int(row.get('year', 0)) if pd.notna(row.get('year')) else 0,\n",
        "            \"category\": str(row.get('category', '')),\n",
        "            \"city\": str(row.get('city', '')),\n",
        "            \"section\": str(row.get('section', '')),\n",
        "            \"image_url\": row.get('url', ''),\n",
        "            \"aesthetic_score\": float(row.get('aesthetic', 0)) if pd.notna(row.get('aesthetic')) else 0,\n",
        "        }\n",
        "\n",
        "        vectors.append({\n",
        "            \"id\": f\"vogue_runway_{row['key']}\",\n",
        "            \"values\": embedding,\n",
        "            \"metadata\": metadata\n",
        "        })\n",
        "\n",
        "    # Upload to Pinecone\n",
        "    if vectors:\n",
        "        index.upsert(vectors=vectors)\n",
        "    return len(vectors)\n",
        "\n",
        "print(f\"\\nProcessing {len(df)} items with pre-computed embeddings...\")\n",
        "print(f\"Using embeddings indexed by key value\")\n",
        "print(f\"Uploading in batches of {BATCH_SIZE}...\\n\")\n",
        "\n",
        "total_uploaded = 0\n",
        "\n",
        "for i in tqdm(range(0, len(df), BATCH_SIZE)):\n",
        "    batch_df = df.iloc[i:i+BATCH_SIZE]\n",
        "    count = process_batch(batch_df, i)\n",
        "    total_uploaded += count\n",
        "\n",
        "print(f\"\\n✓ Upload complete! {total_uploaded} vectors uploaded to Pinecone.\")\n",
        "print(f\"\\nIndex stats: {index.describe_index_stats()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkt0-RYzHaVl"
      },
      "source": [
        "## 6. Test Multimodal Search\n",
        "\n",
        "Test text queries against image embeddings - this is CLIP's superpower!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "s1H4aS71HaVl",
        "outputId": "c20ed870-400a-49f6-bcfb-50206ddfb363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Query: 'elegant evening gown'\n",
            "============================================================\n",
            "\n",
            "1. Score: 0.293\n",
            "   Designer: Jenny Packham\n",
            "   Fall 2022.0\n",
            "   Category: Ready-to-Wear\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/62223957921b9eb00286c356/00017-jenny-packham-fal...\n",
            "\n",
            "2. Score: 0.288\n",
            "   Designer: Marchesa Notte\n",
            "   Resort 2020.0\n",
            "   Category: None\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/5d1a684464290300083ece20/00001-Marchesa-Notte-re...\n",
            "\n",
            "3. Score: 0.288\n",
            "   Designer: Luisa Beccaria\n",
            "   Spring 2019.0\n",
            "   Category: Couture\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/5c49caf9153d8a2d1ae2ffdd/00002-Luisa-Beccaria-Co...\n",
            "\n",
            "============================================================\n",
            "Query: 'minimalist black dress'\n",
            "============================================================\n",
            "\n",
            "1. Score: 0.296\n",
            "   Designer: Theory\n",
            "   Resort 2019.0\n",
            "   Category: None\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/5b054cc79069fc6a729d51e0/00019-theory-vogue-reso...\n",
            "\n",
            "2. Score: 0.286\n",
            "   Designer: Schiaparelli\n",
            "   Spring 2023.0\n",
            "   Category: Couture\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/63ce82596612476c0db22aa3/00083-schiaparelli-spri...\n",
            "\n",
            "3. Score: 0.283\n",
            "   Designer: Cong Tri\n",
            "   Spring 2022.0\n",
            "   Category: Ready-to-Wear\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/6194053562d40458c671b773/00020-CongTri-Spring-22...\n",
            "\n",
            "============================================================\n",
            "Query: 'tweed jacket'\n",
            "============================================================\n",
            "\n",
            "1. Score: 0.305\n",
            "   Designer: Paul Smith\n",
            "   Fall 2007.0\n",
            "   Category: Menswear\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/55c6517d08298d8be2228ec5/00160m.jpg...\n",
            "\n",
            "2. Score: 0.303\n",
            "   Designer: Ralph Lauren\n",
            "   Spring 2023.0\n",
            "   Category: Ready-to-Wear\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/63493eba996ebc04812e24d4/00002-ralph-lauren-spri...\n",
            "\n",
            "3. Score: 0.291\n",
            "   Designer: Brunello Cucinelli\n",
            "   Fall 2018.0\n",
            "   Category: Menswear\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/5a5aa7559838bb16c00fb678/22-brunello-cucinelli-f...\n",
            "\n",
            "============================================================\n",
            "Query: 'vintage cocktail dress'\n",
            "============================================================\n",
            "\n",
            "1. Score: 0.283\n",
            "   Designer: Luisa Beccaria\n",
            "   Fall 2021.0\n",
            "   Category: Ready-to-Wear\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/603a499f2b4ed9246fc2c3d9/00017-Luisa-Beccaria-Fa...\n",
            "\n",
            "2. Score: 0.277\n",
            "   Designer: Laura Garcia\n",
            "   Fall 2019.0\n",
            "   Category: Ready-to-Wear\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/5c59d1df7005522eb8fc35a9/00001-laura-garcia-new-...\n",
            "\n",
            "3. Score: 0.275\n",
            "   Designer: Luisa Beccaria\n",
            "   Spring 2019.0\n",
            "   Category: Couture\n",
            "   City: None\n",
            "   Image: https://assets.vogue.com/photos/5c49cae636babf2d6bee7059/00011-Luisa-Beccaria-Co...\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load CLIP text encoder for queries\n",
        "model = SentenceTransformer('clip-ViT-B-32')\n",
        "\n",
        "# Test queries\n",
        "test_queries = [\n",
        "    \"elegant evening gown\",\n",
        "    \"minimalist black dress\",\n",
        "    \"tweed jacket\",\n",
        "    \"vintage cocktail dress\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Encode text query with CLIP\n",
        "    query_embedding = model.encode(query).tolist()\n",
        "\n",
        "    # Search against image embeddings\n",
        "    results = index.query(\n",
        "        vector=query_embedding,\n",
        "        top_k=3,\n",
        "        include_metadata=True\n",
        "    )\n",
        "\n",
        "    for i, match in enumerate(results['matches'], 1):\n",
        "        print(f\"\\n{i}. Score: {match['score']:.3f}\")\n",
        "        print(f\"   Designer: {match['metadata']['designer']}\")\n",
        "        print(f\"   {match['metadata']['season']} {match['metadata']['year']}\")\n",
        "        print(f\"   Category: {match['metadata']['category']}\")\n",
        "        print(f\"   City: {match['metadata']['city']}\")\n",
        "        if match['metadata'].get('image_url'):\n",
        "            print(f\"   Image: {match['metadata']['image_url'][:80]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWw_hXGzHaVl"
      },
      "source": [
        "## Done! Multimodal Search Ready\n",
        "\n",
        "Your Vogue archive now uses **image embeddings** in the database.\n",
        "\n",
        "When users search with text, CLIP matches:\n",
        "- Text query → Image embeddings\n",
        "- This finds visually similar runway looks based on semantic understanding\n",
        "\n",
        "**Benefits:**\n",
        "✓ Faster processing (no embedding generation needed)\n",
        "✓ Better visual understanding (searches actual image features)\n",
        "✓ True multimodal CLIP search (text-to-image matching)\n",
        "\n",
        "Next steps:\n",
        "1. Deploy the API (see ../api/)\n",
        "2. Your React Native app is already configured!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}